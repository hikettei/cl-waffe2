<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>cl-waffe2/vm.nodes - cl-waffe2 Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "cl-waffe2/vm.nodes";
        var mkdocs_page_input_path = "nodes.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> cl-waffe2 Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../install/">Install</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../overview/">Tutorials</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../Tips/">Tips</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utils/">cl-waffe2</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">cl-waffe2/vm.nodes</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#representing-shapes-before-and-after-the-operation">Representing shapes before and after the operation.</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#introducing-subscript-dsl">Introducing Subscript DSL</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#basic-grammar">Basic Grammar</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#assigned-task">Assigned task</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#determine-rules">Determine Rules</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#initial-value-of-table">Initial value of table</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#api-create-subscript-p">API: create-subscript-p</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#abstractnode">AbstractNode</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#class-abstractnode">[class] AbstractNode</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-defnode">[macro] defnode</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#effects">Effects</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#inputs">Inputs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example">Example</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#effects_1">Effects</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#inputs_1">Inputs</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-define-impl-op">[macro] define-impl-op</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-define-op">[macro] define-op</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#effects_2">Effects</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example_1">Example</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-set-save-for-backward">[function] set-save-for-backward</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-read-save-for-backward">[function] read-save-for-backward</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-with-reading-save4bw">[macro] with-reading-save4bw</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-with-setting-save4bw">[macro] with-setting-save4bw</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#composite">Composite</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#class-composite">[class] Composite</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#generic-on-print-object">[generic] on-print-object</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-defmodel">[macro] defmodel</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#inputs_2">Inputs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example_2">Example</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#dispatching-on-call-method">Dispatching on-call-&gt; method</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#on-call-is-a-list">on-call-&gt; is a list</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-defmodel-as">[macro] defmodel-as</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#example_3">Example</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#inputs_3">Inputs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#effects_3">Effects</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#notes">Notes</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#events-for-embedding-jit-generated-code-in-runtime">Events for Embedding JIT-Generated Code in runtime</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../generic-tensor/">cl-waffe2/vm.generic-tensor</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../vm/">cl-waffe2/vm</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../base-impl/">[Functions] cl-waffe2/base-impl</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../base-impl-nodes/">[Nodes] cl-waffe2/base-impl</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../distributions/">cl-waffe2/distributions</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../nn/">cl-waffe2/nn</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../optimizer/">cl-waffe2/optimizers</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../lisp-tensor-backend/">cl-waffe2/backends.lisp</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cpu-tensor-backend/">cl-waffe2/backends.cpu</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cpu-jit-tensor-backend/">cl-waffe2/backends.jit.cpu</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">cl-waffe2 Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li>cl-waffe2/vm.nodes</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="formulating-computation-nodes">Formulating Computation Nodes</h1>
<p>The package <code>:cl-waffe2/vm.nodes</code> provides a features on <code>AbstractNode</code> and <code>Composite</code>, which is a fundamental data structure to represent computation node. <code>AbstractNode</code> is the smallest unit of the operation in the network, and <code>Composite</code> is a class which bundles several <code>AbstractNodes</code> (<code>Composite=nn.Module or Model</code> in other frameworks).</p>
<p>The role of node and model is completely different. To perform operations with <code>AbstractNode</code> we have to step a two steps: <code>General Definition</code> and <code>Device Specific Implementations</code>. <code>AbstractNode</code> is defined by the macro <code>defnode</code> with its specifications but forward implementation. The macro <code>define-impl</code> or <code>define-impl-op</code> will provide device-specific implementations for each AbstractTensor. The differences between <code>define-impl</code> and <code>define-impl-op</code> is that: The :forward definition is given by a macro or a function respectively. With <code>define-impl</code> macro and the <code>call-with-view</code> function, you can create a operation which optimizes, fuses, and collapses  the order of iteration, schedules multi-threading, and computes view offsets in advance with a simple form.</p>
<p>On the other hand, since <code>Composite</code> is user to bundle several nodes, it is not only used to juse represent Neural Network Model (e.g.: <code>LinearLayer</code> <code>Conv2D</code>...) but compiled into <code>function</code> or <code>AbstractNode</code> with the <code>defmodel-as</code> macro by tracing its computation node declared in the <code>:call-&gt;</code> method. However, to do this, you have to declare these information in advance: <code>The rank/shape of tensors, the number of arguments, and which operations are In-place?</code>. This is also true for <code>AbstractNode</code> and cl-waffe2 introduced an small DSL to represent this, <code>Subscript DSL (:where ...)</code>.</p>
<p>In short word, Subscript DSL is used to:</p>
<ul>
<li>
<p>For AbstractNode, declares the transmission states of the operation (MUST)</p>
</li>
<li>
<p>For Composite, in order to trace the network, it declares the transmission state of operation (Optional)</p>
</li>
</ul>
<p>Accordingly, this document is divided to three sections.</p>
<ul>
<li>
<p>The specification of Subscript DSL</p>
</li>
<li>
<p>AbstractNode</p>
</li>
<li>
<p>Composite</p>
</li>
</ul>
<p>And an overview of APIs is here:</p>
<pre><code class="language-lisp">[AbstractNode] The fundamental unit of forward/backward propagations.
 defnode - Declares a general definition of AbstractNode
      L define-impl     Implements a AbstractNode. Its forward definition is given as a macro (to inline/call-with-view), later (compile nil body) is called, and cached when :compile-when-cache=t.
      L define-impl-op  Implements as a lambda function.

define-op = defnode + define-impl-op

[Composite] Bundles several AbstractNodes, defined by defmodel macro.
  defmodel - Defines a new Composite
     L defmodel-as Redefining the existing Composite as a function or AbstractNode to reduce compiling time, to use cl-waffe2 as a define-by-run library.
</code></pre>
<p>cl-waffe2 VM sorts and compiles the network of <code>AbstractNode</code> into a <code>cl-waffe2 IR (Extended Wengert List)</code> and operations are performed. And, <code>AbstractNode</code> is used to represent an blueprint of lambda functions. Both of AbstractNode and Composite are the CLOS class.</p>
<h2 id="representing-shapes-before-and-after-the-operation">Representing shapes before and after the operation.</h2>
<p>When defining an operation in cl-waffe2 with a <code>defnode</code> macro, the shape of the matrix used in the operation must also be defined in the <code>:where</code> keyword.</p>
<p>This is a Shaping API, and responsible for shape inspection of all operations, and tracing the network.</p>
<h2 id="introducing-subscript-dsl">Introducing Subscript DSL</h2>
<p>I assume you have already seen <code>defnode</code> macro. This macro takes a strange syntax language after :where keyword.</p>
<pre><code class="language-lisp">(defnode (TransposeNode (myself)
            :where (A[~ i j] -&gt; A[~ j i])
         ...))

(defnode (ScalarAdd (myself)
            :where (A[~] Scal[scal] -&gt; A[~] where scal = 1)
        ...))

(defnode (ReshapeNode (myself tensor after &amp;aux (before (shape tensor)))
            :where (A[before] -&gt; A[after])
        ...))
</code></pre>
<p>This is a DSL (Domain Specific Language) called <code>Subscript DSL</code>, which is used to notate the pointer and shape to be handled before and after the operation.</p>
<p>For example, <code>TransposeNode</code> is said to be:</p>
<ol>
<li>
<p>Before and after the operation, we use the same pointer.</p>
</li>
<li>
<p>A is a tensor with more than two dimensions, and after the operation, transposed the last two axes. (i.e.: A=(10 5 2), (10 2 5) is returned)</p>
</li>
</ol>
<p><code>ScalarAdd</code> is said to be:</p>
<ol>
<li>
<p>The first argument <code>A</code> can be anything. The second argument <code>Scal</code> is a scalar tensor.</p>
</li>
<li>
<p>The returned tensor shares the pointer with the given <code>A</code>.</p>
</li>
</ol>
<p><code>ReshapeNode</code> is:</p>
<ol>
<li>
<p>Before and after the operation, pointers are common.</p>
</li>
<li>
<p>The shape of A will be transformed from <code>before</code> into <code>after</code></p>
</li>
</ol>
<h3 id="basic-grammar">Basic Grammar</h3>
<p>Let's start with learning the grammar.</p>
<p>One line code of Subscript DSL follows this format:</p>
<pre><code>[Before The Operation] -&gt; [After The Operation] where [symbol = expression (Optional)] ...
</code></pre>
<p>Note that:</p>
<ol>
<li>
<p>the pharse <code>where [symbol = expression (Optional)] ...</code> is <strong>Optional</strong></p>
</li>
<li>
<p>One Subscript DSL place can include one line of code.</p>
</li>
<li>
<p>[Before The Operation] and [After The Operation] has the common grammar rule.</p>
</li>
</ol>
<p>Let <code>&lt;Arguments&gt;</code> be a grammar rule of [Before The Operation] and [After The Operation], <code>&lt;Arguments&gt;</code> can be defined as:</p>
<pre><code>&lt;Arguments&gt; ::= &lt;Arguments&gt; &lt;Argument&gt;
&lt;Argument&gt; ::= &lt;PointerName&gt; [ &lt;SubScripts&gt; ] | NIL

&lt;PointerName&gt; ::= Symbol // the same as CL's symbol.

&lt;SubScripts&gt;  ::= &lt;Subscripts&gt; &lt;Subscript&gt;
&lt;Subscript&gt;   ::= Symbol | NIL
</code></pre>
<p>To put it bluntly, <Argument> can be a sequence of:</p>
<pre><code class="language-c">PointerName[SubScripts]

// SubScripts can be one of: [A], [A B] [~ i j] etc...
</code></pre>
<h3 id="assigned-task">Assigned task</h3>
<pre><code>A[a b] B[a b] -&gt; B[a b]
</code></pre>
<p>In the DSL above, <code>A</code> and <code>B</code> indicates the name of pointer, they're not needed to be defined in advance.</p>
<p>On the other hand <code>a</code> and <code>b</code> inside [ ... ], indicates subscripts of <code>A</code> and <code>B</code>, DSL's assigned work is to inference these <strong>undetermined symbols</strong> from:</p>
<ol>
<li>
<p>determined symbol from <code>where</code> pharse and symbols in arguments of constructor.</p>
</li>
<li>
<p>Shape of the given inputs at runtime.</p>
</li>
</ol>
<p>If any, DSL compiles and display a report on <code>Shape-Error</code> before performing the operation.</p>
<pre><code class="language-lisp">(!add (randn `(3 2)) (randn `(2 4)))
;; will produce...

[cl-waffe] Shaping-Error: Couldn't step forward because of shape-error.

The operation was : &lt;Node: ADDNODE-CPUTENSOR (A[~] B[~] -&gt; A[~])&gt;

Input(s)            : ((3 2) (2 4))
Predicted Output(s) : ((3 2))

Here's a list of reports.

1. Couldn't idenfity ~: ~ is determined as 3 
 butgot: 2.
 Excepted ~ = (3 2), butgot: (2 4)

Also, these reports could be helpful for you (calculated ignoring the first errors.)

2. Couldn't idenfity ~: ~ is determined as 2 
 butgot: 4.
 Excepted ~ = (3 2), butgot: (2 4)
</code></pre>
<h3 id="determine-rules">Determine Rules</h3>
<pre><code>(defnode (ExampleNode (myself)
            :where (A[~ i j] B[~ j k] C[~ k i] -&gt; C[~ k i])
         ...))
</code></pre>
<p>Symbols used in subscripts has a two state:</p>
<ol>
<li>
<p>Determined (those that can say i=1, j=2!)</p>
</li>
<li>
<p>Undetermined (those that cannot say i=1, j=2)</p>
</li>
</ol>
<p>Before doing <code>(call (ExampleNode) ...)</code>, we create a table which stores determined/undetermined symbols and corresponding values.</p>
<pre><code>[TABLE]
~  -&gt; ? // Undetermined before runtime
i  -&gt; ? // Undetermined before runtime
j  -&gt; ? // Undetermined before runtime
k  -&gt; ? // Undetermined before runtime
</code></pre>
<p>The moment we do <code>(call (ExampleNode) TensorA TensorB TensorC)</code>, we will be able to inference the value of <code>i</code> <code>j</code> <code>k</code> from the shape of given TensorA, TensorB, and TensorC.</p>
<p>For Example, Let TensorA be a <code>2x3x4</code> Matrix, then the table become:</p>
<pre><code>[TABLE]
~  -&gt; 2
i  -&gt; 3
j  -&gt; 4
k  -&gt; ? 
</code></pre>
<p>Then continue to do the same thing for TensorB. Let TensorB be a <code>2x4x9</code> Matrix, then the table become:</p>
<pre><code>[TABLE]
~ -&gt; 2
i -&gt; 3
j -&gt; 4
k -&gt; 9
</code></pre>
<p>Last, applying this operation into TensorC, but what if I gave the wrong shape to TensorC? Let TensorC be a <code>999x999x999</code> Matrix. (Obviously this is wrong).</p>
<pre><code>[TABLE]
~ -&gt; 2 // ≠999
i -&gt; 3 // ≠999
j -&gt; 4 // ≠999
k -&gt; 9 // ≠999
</code></pre>
<p>All subscripts in the table do not match with 999, resuting in shape-error.</p>
<p>In that case, we can try again the operation with giving the correct shape to TensorC. Let TensorC be <code>2x9x3</code> Matrix.</p>
<pre><code>[TABLE]
~ -&gt; 2 // =2
i -&gt; 3 // = 3
j -&gt; 4 // 
k -&gt; 9 // = 9
</code></pre>
<p>All subscripts passed! (puts error If there's still undetermined symbol.)</p>
<p>Using the determined table, we can also inference the shape of output tensor. The returned tensor is the shape of <code>(~ k i)</code>, that is, <code>(2 9 3)</code>. This operation can be done in a chain of lazy-evaluated nodes.</p>
<p>Now, moving on to another topic, subscripts can be one of them.</p>
<pre><code>[TABLE]

a = 1 // Fixnum

b = `(1 2) // List consisted of fixnum

~ = `(1 2 3) // ~ is a special symbol which represents batched-input.
</code></pre>
<p>DSL flattens the list in the subscript. (e.g.: <code>b=(1 2)</code> in <code>A[b]</code> is the equivalent to <code>A[1 2]</code>)</p>
<p><strong>Note that</strong> ~ is a reserved word by cl-waffe2 and has a special rule:</p>
<ol>
<li>
<p>~ is used to express dimensions from 0 to N</p>
</li>
<li>
<p>~ can only be used once for one input of subscript.</p>
</li>
<li>
<p>In tables, ~ is interpreted as one of: <code>NIL</code> or <code>List</code></p>
</li>
</ol>
<p>In addition, ~ has a three behaviour:</p>
<ol>
<li>
<p>If ~ never appears in [Before The Operation] and [After The Operation] parts, the length of ~ could be Any.</p>
</li>
<li>
<p>If ~ appears more than once, the length of ~ and content should be common.</p>
</li>
<li>
<p>If ~ appears only in [After The Operation], returns error because we can't determine ~.</p>
</li>
</ol>
<p>In conclusion, I believe introducing Subscript DSL produces two benefits:</p>
<ol>
<li>
<p>Rigorous Shape Inspection in all operations with small code, and produce better Shape-Error (Initially I'm inspired in: <a href="https://github.com/dimforge/nalgebra">nalgebra</a>).</p>
</li>
<li>
<p>JIT Compiler can use a shape of given arguments in advance. (If only CL has a const-generics like Rust, Subscript DSL isn't needed anymore!).</p>
</li>
</ol>
<h3 id="initial-value-of-table">Initial value of table</h3>
<p>In order to give a initial value to tables, you can declare symbols with initial value.</p>
<p><strong>Using where pharse in :where form</strong></p>
<p>Add this form to your <code>:where</code> form.</p>
<pre><code class="language-lisp">;; Syntax is that: Symbol-Name = Expression

(defnode (...
    :where (A[i] B[j] -&gt; C[k] where i = 1 j = 2 k = 3)
    ....
</code></pre>
<p>will produce:</p>
<pre><code>[TABLE]
i = 1
j = 2
k = 3
</code></pre>
<p>Using arguments declared in <code>constructor</code>.</p>
<pre><code class="language-lisp">(defnode (ExampleNode (self i)
             :where (A[~] -&gt; A[i]))
        ...)
</code></pre>
<p>Arguments used in constructor, will automatically interpreted as <code>initial value</code>. (e.g.: <code>i</code> is a initial value.)</p>
<pre><code>[TABLE]
~ = ?
i = i
</code></pre>
<p>That is, when <code>ExampleNode</code> is initialized with <code>(ExampleNode 3)</code>, the table become:</p>
<pre><code>[TABLE]
~ = ?
i = 3
</code></pre>
<ol>
<li>arguments of constructor</li>
</ol>
<h3 id="api-create-subscript-p">API: create-subscript-p</h3>
<p><code>(create-subscript-p subscripts &amp;key macroexpand fixed return-body)</code></p>
<p>Inputs:</p>
<ol>
<li>
<p>macroexpand[Boolean] If t, displays the generated program.</p>
</li>
<li>
<p>fixed[Boolean] If t, ~ is ignored.</p>
</li>
<li>
<p>return-body[Boolean] If t, the returned is S-exp.</p>
</li>
</ol>
<p>Outputs:</p>
<p><code>(values compiled-function To-Refer-Pointer-Idx Broadcastable_List)</code></p>
<p>Example: (TODO)</p>
<h2 id="abstractnode">AbstractNode</h2>
<h2 id="class-abstractnode">[class] AbstractNode</h2>
<p>AbstractNode is a CLOS class to represent operations.</p>
<p>Can be created by a function <code>(AbstractName ...)</code> declared by the defnode macro.</p>
<p>In order to step the computation: <code>(forward node arg1 arg2 ...)</code> (using a <code>call</code> instead of <code>forward</code> is ok)</p>
<p>And backward: <code>(backward node prev-gradient arg1 arg2 ...)</code></p>
<h2 id="macro-defnode">[macro] defnode</h2>
<pre><code class="language-lisp">(defnode (abstract-name
           (self &amp;rest constructor-arguments)
            &amp;key
              (where t)
              (out-scalar-p nil)
              (slots nil)
              (save-for-backward nil)
              (backward nil)
              (extends nil)
              (documentation &quot;&quot;))
           &amp;body constructor-body)
</code></pre>
<p>Declares a new <code>AbstractNode</code>.</p>
<h3 id="effects">Effects</h3>
<ul>
<li>defines a class (subclass of <code>AbstractNode</code>) named <code>abstract-name</code></li>
<li>defines a fucntion which initializes the defined node.</li>
</ul>
<h3 id="inputs">Inputs</h3>
<ul>
<li><code>abstract-name</code>[symbol] indicates the name of class, and constructor.</li>
<li>
<p>extends[list] set a list of symbols, the class is defined with extending them.</p>
</li>
<li>
<p><code>(self &amp;rest constructor-arguments)</code> declares the arguments of the constructor function, which <code>cosntructor-body</code> uses. </p>
</li>
<li>
<p>slots[list] Describe the slots which node has as if defclass. Tips: In order to make it shorter to create a constructor, if initargs (i.e.: <code>:initarg :XXX</code>) is the same as the keyword name of the argument, the initform is replaced with the argument.</p>
</li>
<li>
<p>where[SubscriptDSL] Put here the Subscript DSL (MUST)</p>
</li>
<li>
<p>out-scalar-p [Boolean] Set t if the node returns a ScalarTensor.</p>
</li>
<li>
<p>backward [list] This form is optional. The backward receives arguments like: <code>(dout var1 var2...)</code> and return tensors which is lazy-evaluated. (See examples). You can set this form as nil, but in that case each <code>define-impl</code> and <code>define-impl-op</code> must have a backward slot.</p>
</li>
<li>
<p>documentation [String]</p>
</li>
</ul>
<h3 id="example">Example</h3>
<pre><code class="language-lisp">;; Tips
(defnode (ExampleNode (self arg)
            :slots ((arg :initarg :arg))))

(slot-value (ExampleNode 10) 'arg) ;; =&gt; 10

(defnode (MatMulNode-Revisit (myself dtype &amp;key transpose-a transpose-b)
      :where (A[~ i j] B[~ j k] C[~ i k] -&gt; C[~ i k])
      :slots ((transpose-a :initarg :transpose-a :type boolean :reader trans-a?)
          (transpose-b :initarg :transpose-b :type boolean :reader trans-b?))
      :backward ((self dout da db do)
                     ;; dout=previous gradient, :save-for-backward is set to (t t nil).
                     ;; so da/db is a copy of variable.
             (declare (ignore do))
                     ;; Set nil to the direction gradients aren't produced.
             (values
              (!matmul dout (!t db))
              (!matmul (!t da) dout)
              nil))
      :documentation &quot;
```math
C\gets{gemm(1.0, A, B, 0.0, C)}
</code></pre>
<p>"))</p>
<pre><code>
You can invoke the forward/backward by using the method forward/backward. `(forward node arg1 arg2...)` `(backward node dout1 arg1 arg2...).
`

## [macro] define-impl

```lisp
(define-impl (abstract-name &amp;key (device t) (extends nil) (cache-when-compiled t) (reject-p nil))
        &amp;key (save-for-backward nil) (forward nil) (backward nil))
</code></pre>
<p>Defines an implementation of <code>abstract-name</code> which is already declared by <code>defnode</code> macro, with :forward=macro and later compiled.</p>
<h3 id="effects_1">Effects</h3>
<p>Defines a CLOS class named <code>abstract-name-device</code> extends <code>abstract-name</code></p>
<h3 id="inputs_1">Inputs</h3>
<p><code>device</code>[symbol or t] Set the name of AbstractTensor which the impl supports for. Set t to anything.</p>
<p><code>extends</code>[nil or list] In addition to extend <code>abstract-name</code>, the defined implementation will extends the given classses.</p>
<p><code>cache-when-compiled</code>[boolean] Set T to cache the forward definiton depending on dtypes, ranks, devices of arguments. You can set this to NIL but in terms of performance it is not recommended (runtime-compiling overhead is unignorable!) Instead, in that case, using <code>define-impl-op</code> would be nice.</p>
<p><code>save-for-backward</code>[list of boolean] For backward computation, the corresponding position of received variables will be produce a copy. You can check how it works with <code>(disassemble-waffe2-ir toplevel)</code> function and SV4BW(...) is exactly this. In backward, <code>((self dout x y) ...)</code> will receive the copy.</p>
<p><code>forward</code>[body] Follows this format: <code>((self arg1 arg2 ...) &lt;&lt;macro-body&gt;&gt;)</code> and the form must return S-expression later compiled by `(compile nil ...)</p>
<p><code>backward</code>[body] Follows this format: <code>((self prev-gradient arg1 arg2 ...) (values arg1.grad arg2.grad))</code> Note that the form is given by a function, and computation nodes are continuous. Not a macro.</p>
<p><code>reject-p</code>[nil or function] Set a lambda function returning nil or T. The function is called with arguments: <code>(function constructor-args1 constructor-args2 ...)</code>. In the case the function returned T, the method dispatching is ignored. You can use this method to ignore a certain dtype as a :forward arguments for example.</p>
<h2 id="macro-define-impl-op">[macro] define-impl-op</h2>
<p>Gives an implementation of <code>abstract-name</code> as a function form.</p>
<pre><code class="language-lisp">(define-impl-op ((abstract-name &amp;key (device t) (extends nil) (reject-p nil)) &amp;key forward backward))
</code></pre>
<h2 id="macro-define-op">[macro] define-op</h2>
<p><code>define-op</code> = <code>defnode</code> + <code>define-impl-op</code></p>
<p>Defines a differentiable AbstractNode which its definition is given by a function.</p>
<pre><code class="language-lisp">(define-op (name (self &amp;rest constructor-args) where slots out-scalar-p save-for-backward-names forward backward documentation extends-fw extends-bw) &amp;body body)
</code></pre>
<h3 id="effects_2">Effects</h3>
<p>This macro defines:</p>
<ol>
<li>two <code>AbstractNodes</code> named <code>name</code> and <code>name-backward</code> (if backward is given)</li>
</ol>
<h3 id="example_1">Example</h3>
<pre><code class="language-lisp">(define-op (TestAdd-Scalar (self)
        :where (A[scal] B[scal] -&gt; A[scal] where scal = 1)
            :out-scalar-p t
        :forward ((self a b)
              (make-tensor
               (+ (tensor-vec a)
              (tensor-vec b))))
        :backward ((self dy)
               (values dy dy))))
</code></pre>
<h2 id="function-set-save-for-backward">[function] set-save-for-backward</h2>
<pre><code class="language-lisp">(set-save-for-backward self name tensor)
</code></pre>
<p>The function <code>set-save-for-backward</code> saves the given <code>tensor</code> to the <code>name</code> slot of self for a future call of backward.</p>
<p>This function is dedicated to the macro <code>define-static-node</code>, so it should be placed at the forward/backward definition of the macro, otherwise, the wrong function is binded which returns simple-error. In addition, The place to save the tensor, should be also declared in <code>:save-for-backward-names</code> in the <code>define-static-node</code> macro.</p>
<p>Note that this function is ignored in specific conditions: <code>*no-grad*</code> is t or <code>set-save-for-backward</code> in the forward definition in the forward definition. (i.e.: the place which is never called.)</p>
<p>See also: <code>read-save-for-backward</code> <code>with-setting-sv4bw</code> <code>with-reading-sv4bw</code> <code>define-static-node</code></p>
<h2 id="function-read-save-for-backward">[function] read-save-for-backward</h2>
<pre><code class="language-lisp">(read-save-for-backward self name)
</code></pre>
<p>Reading the slot of <code>name</code> in <code>self</code>, the function <code>read-save-for-backward</code> returns a saved tensor by <code>set-save-for-backward</code>.</p>
<p>For the same reason of <code>set-save-for-backward</code>, this function should be placed at right place.</p>
<h2 id="macro-with-reading-save4bw">[macro] with-reading-save4bw</h2>
<pre><code class="language-lisp">(with-reading-save4bw ((&amp;rest input-forms) &amp;body body))

input-form = (variable-place save-for-backward-name)
</code></pre>
<p>Reading the save-for-backward of currently working node, the macro binds each <code>variable-place</code> the stored tensor.</p>
<h2 id="macro-with-setting-save4bw">[macro] with-setting-save4bw</h2>
<pre><code class="language-lisp">(with-setting-save4bw ((&amp;rest input-forms) &amp;body body))
input-form = (save-place tensor)
</code></pre>
<p>Saves the given tensors to save-place, in the currently working node.</p>
<h2 id="composite">Composite</h2>
<h2 id="class-composite">[class] Composite</h2>
<p>Its <code>call</code> bundles several AbstractNode. It is not only used to represent a neural network but also convert nodes into functions or abstractnodes. You can forward composites with <code>(call composite arg1 arg2...)</code>. For the most case, composites are defined by the defmodel macro.</p>
<h3 id="generic-on-print-object">[generic] on-print-object</h3>
<pre><code>(on-print-object model stream)
</code></pre>
<p>This generic function is used to customize how the model is printed on the display.</p>
<pre><code>&lt;Composite: NAME{...}(
    [...] &lt;- The content of here is depends on on-print-object
    [PARAMTETERS]
)
</code></pre>
<h2 id="macro-defmodel">[macro] defmodel</h2>
<pre><code>(defmodel ((name
         (self-name &amp;rest constructor-arguments)
              &amp;key
               (slots nil)
               (initargs)
                       (where nil)
               (on-call-&gt; nil)
               (documentation &quot;&quot;))
            &amp;body constructor-body)
</code></pre>
<p>Defines a composite named <code>name</code>, and constructor function which also named <code>name</code> and receives <code>constructor-arguments</code> as arguments. The main process of its forward process is described in the <code>on-call-&gt;</code> slots.</p>
<h3 id="inputs_2">Inputs</h3>
<p><code>name[Symbol]</code> the macro defines an class and constructor function named after it.</p>
<p><code>(self-name &amp;rest constructor-arguments)</code> An initializer form of <code>constructor function</code>.</p>
<p><code>slots ((slot-option1) (slot-option2) ...)</code> Parameters of the inherited Composite class. It has the same syntax as defclass slots`</p>
<p><code>initargs (:accessor-name1 accessor-init-form1 :accessor-name2 accessor-init-form2 ...)</code> Unlike structures, CLOS classes are somewhat more cumbersome to initialise parameters. To make this process simple, put here initializer forms in advance likewise we do <code>(make-instance class-name ...)</code>.</p>
<p><code>documentation[String]</code></p>
<p><code>on-call-&gt; [One of: nil symbol-name function list]</code> The main proces of its forward process, later called with <code>(call model ...)</code> method. This method must be continuous from the given arguments.</p>
<p><code>where[Subscript DSL] (Optional)</code> If you're planning to use <code>defmodel-as</code> macro, this form is needed.</p>
<h3 id="example_2">Example</h3>
<pre><code class="language-lisp">(defmodel (ExampleLayer (self features)
               ;; Options/Utils Here,
               :slots    ((param :initarg :param))
               :initargs (:param (make-tensor `(,features) :requires-grad t))
               :documentation &quot;ExampleLayer is a ...&quot;)

    ;; After make-instance is called, the form below is called.
    ;; make-instance -&gt; make-instance :after -&gt; this form.

    (print self)     ;; &lt;- Initialized ExampleLayer
    (print features) ;; &lt;- constructor-arguments are also used here.
    (print &quot;ExampleLayer is created!&quot;))

;; The model you created, works like:
(let ((layer (ExampleLayer 10)))
    (call layer ...))
</code></pre>
<pre><code class="language-lisp">(defmodel (Softmax-Model (self)
       :where (X[~] -&gt; [~])
       :on-call-&gt; ((self x)
               (declare (ignore self))
               (let* ((x1 (!sub x (!mean x  :axis 1 :keepdims t)))
                          (z  (!sum   (!exp x1) :axis 1 :keepdims t)))
                           (!div (!exp x1) z)))))

;; Keep Using Lazily...
(proceed (call (Softmax-Model) (randn `(10 10)))
{CPUTENSOR[float] :shape (10 10) :named ChainTMP33497 
  :vec-state [computed]
  ((0.04800622   0.118814774  0.050377533  ~ 0.053051848  0.050124187  0.25575548)                    
   (0.15909052   0.11368358   0.12642372   ~ 0.114795394  0.033397682  0.07605342)   
                 ...
   (0.035624444  0.24828684   0.109363265  ~ 0.020787988  0.027314318  0.04515641)
   (0.030307569  0.24117047   0.03900468   ~ 0.014522874  0.036584295  0.0971196))
  :facet :input
  :requires-grad NIL
  :backward &lt;Node: PROCEEDNODE-T (A[~] -&gt; A[~])&gt;}

(defmodel-as (Softmax-Model) :asif :function :named softmax-static)

;; No compiling overhead
(softmax-static (randn `(10 10)))

{CPUTENSOR[float] :shape (10 10) :named ChainTMP33788 
  ((0.16722792   0.018530384  0.014159603  ~ 0.035353966  0.06128503   0.13559735)                    
   (0.14498742   0.11881006   0.0692616    ~ 0.03911829   0.10358454   0.02131605)   
                 ...
   (0.055657785  0.44042623   0.030706322  ~ 0.11048273   0.0097645    0.11959953)
   (0.059088983  0.11067564   0.120767005  ~ 0.15042976   0.06570089   0.20548664))
  :facet :input
  :requires-grad NIL
  :backward NIL}
</code></pre>
<h3 id="dispatching-on-call-method">Dispatching on-call-&gt; method</h3>
<ul>
<li>
<p><code>on-call-&gt; is nil</code> In that case, users must define the call definiton manually like <code>(defmethod call ((model YourComposite) arg1 arg2) ...)</code>.</p>
</li>
<li>
<p><code>on-call-&gt; is symbol</code> In that case, the composite invokes the method named <code>symbol</code> when call is invoked.</p>
</li>
</ul>
<pre><code class="language-lisp">;; Set :on-call-&gt; call-example-layer


(defmethod call-example-layer ((model ExampleLayer) x y)
    (print &quot;call-example-layer is used!&quot;))
</code></pre>
<pre><code class="language-lisp">(call (ExampleLayer 10) tensor) ;; call-example-layer is used!
</code></pre>
<h3 id="on-call-is-a-list"><code>on-call-&gt;</code> is a list</h3>
<p>Directly defines a <code>call</code> method. Arguments must be: <code>(self arg1 arg2...)</code></p>
<pre><code class="language-lisp">...
    :on-call-&gt; ((self x)
                (!sin x))
</code></pre>
<h2 id="macro-defmodel-as">[macro] defmodel-as</h2>
<pre><code class="language-lisp">(defmodel-as target-model &amp;key (where nil) (asif :function) (named nil) (differentiable nil))
</code></pre>
<p>Redefines a Composite as a new function or AbstractNode specified in the <code>:asif</code> keyword. Further functions or <code>Differentiable AbstractNode</code> can be defined based on existing Composites (also called as <code>model</code> and defined by <code>defmodel</code> macro) which bundles several <code>AbstractNodes</code>, as long as <code>:where</code> form is fulfilled.</p>
<p><strong>Note that the expanded form includes eval function! So this macro should be placed in the toplevel!</strong></p>
<h3 id="example_3">Example</h3>
<pre><code class="language-lisp">(defmodel-as (SoftmaxNode) :named static-softmax :asif :function :where (A[~] -&gt; A[~]))
</code></pre>
<h3 id="inputs_3">Inputs</h3>
<p><code>target-model[Composite]</code> a form to initialize the composite. ~~This from is executed before running the code, and accordingly static.~~</p>
<p><code>where[Subscript DSL or null]</code> If the model has no <code>:where</code> declaration, this macro uses this <code>:where</code> form instead. Therefore, as long as <code>defmodel</code> provides <code>:where</code> declaration, this form should be OK if set as nil.</p>
<p><code>named[symbol]</code> this macro will define a new function after <code>named</code>. If set to <code>nil</code>, the macro return a lambda function instead of defining it. If you're trying to define a new <code>AbstractNode</code>, this option should be fulfilled.</p>
<p><code>:asif[keyword]</code> indicates which form the <code>target-model</code> is to be redefined, and could be one of:</p>
<pre><code>─────────────────────────────────────────────────────────────────────────────────────
  asif    |   description
─────────────────────────────────────────────────────────────────────────────────────
:function | Defines a function to be executed immediately that does not create a node.
─────────────────────────────────────────────────────────────────────────────────────
:node     | Defines a AbstractNode which needs to be compiler later
─────────────────────────────────────────────────────────────────────────────────────
</code></pre>
<h3 id="effects_3">Effects</h3>
<p>If <code>named</code> is not <code>NIL</code>, this macro defines a new function or AbstractNode after <code>named</code>.</p>
<h3 id="notes">Notes</h3>
<p>Depending on the <code>device</code> and <code>dtype</code> used of arguments, several methods are compiled and dispatched.</p>
<h2 id="events-for-embedding-jit-generated-code-in-runtime">Events for Embedding JIT-Generated Code in runtime</h2>
<p>If the node is needed to be compiled, compile.NIL</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../utils/" class="btn btn-neutral float-left" title="cl-waffe2"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../generic-tensor/" class="btn btn-neutral float-right" title="cl-waffe2/vm.generic-tensor">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../utils/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../generic-tensor/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
