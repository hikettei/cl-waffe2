<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>cl-waffe2/vm - cl-waffe2 Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "cl-waffe2/vm";
        var mkdocs_page_input_path = "vm.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> cl-waffe2 Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Overview</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../install/">Install</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../overview/">Tutorials</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utils/">cl-waffe2</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../nodes/">cl-waffe2/vm.nodes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../generic-tensor/">cl-waffe2/vm.generic-tensor</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">cl-waffe2/vm</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#parameter-opt-level">[parameter] *opt-level*</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#parameter-logging-vm-execution">[parameter] *logging-vm-execution*</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#struct-wfinstruction">[struct] WfInstruction</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#slots">Slots</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-compile-forward-and-backward">[function] compile-forward-and-backward</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#return">Return</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-accept-instructions">[function] accept-instructions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-disassemble-waffe2-ir">[function] disassemble-waffe2-ir</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#example">Example</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-benchmark-accept-instructions">[function] benchmark-accept-instructions</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#inputs">Inputs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#return_1">Return</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example_1">Example</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#struct-fusionpathquery">[struct] FusionPathQuery</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#macro-defpath">[macro] defpath</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#rules">Rules</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example_2">Example</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#make-query">make-query</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../base-impl/">[Functions] cl-waffe2/base-impl</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../base-impl-nodes/">[Nodes] cl-waffe2/base-impl</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../distributions/">cl-waffe2/distributions</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../nn/">cl-waffe2/nn</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../optimizer/">cl-waffe2/optimizers</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../lisp-tensor-backend/">cl-waffe2/backends.lisp</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cpu-tensor-backend/">cl-waffe2/backends.cpu</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cpu-jit-tensor-backend/">cl-waffe2/backends.jit.cpu</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">cl-waffe2 Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li>cl-waffe2/vm</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="cl-waffe2-vm">cl-waffe2 VM</h1>
<p>The package <code>cl-waffe2/vm</code> is the central of system, and features are focused on low-level stuffs: compiling/optimizing/rewriting cl-waffe2 IRs and how they're executed. So, most of APIs are accesible by convinient API wrappers of other packages.</p>
<ul>
<li>Global Variables<ul>
<li><a href="./#parameter-opt-level">optimization level</a></li>
<li><a href="./#parameter-logging-vm-execution">logging</a></li>
</ul>
</li>
<li>IR and Compiler<ul>
<li><a href="./#struct-wfinstruction">WfInstruction</a></li>
<li><a href="./#function-compile-forward-and-backward">compiler</a></li>
<li><a href="./#function-accept-instructions">acceptor</a></li>
</ul>
</li>
<li>Analyzing compiled codes<ul>
<li><a href="#function-disassemble-waffe2-ir">disassemble</a></li>
<li><a href="#function-benchmark-accept-instructions">profiling</a></li>
</ul>
</li>
<li>Adding Symbolic Diff and Device-Specific Optimization<ul>
<li><a href="./#struct-fusionpathquery">FusionPathQuery</a></li>
<li><a href="./#macro-defpath">defpath</a></li>
</ul>
</li>
</ul>
<h2 id="parameter-opt-level">[parameter] <code>*opt-level*</code></h2>
<p>This parameter indicates the degree of runtime error detection. Whichever you choose, cl-waffe2 never apply something unsafe code transformation. It takes the fixnum from 1 to 3, and the larger, the faster.</p>
<ul>
<li>
<p>Set 1 to use safety-mode, in every instructions, runtime error is checked.</p>
</li>
<li>
<p>Set 2 to use middle-mode, runtime error is checked only when first execution.</p>
</li>
<li>
<p>Set 3 to use fastest-mode, no runtime error checking is done.</p>
</li>
</ul>
<p>Again, whichever levels you choose, the graph cl-waffe2 executes is the same. So the effects on the performance is very small (within &lt; <code>1e-4~1e-5</code> sec).</p>
<p>In default, set to 2.</p>
<h2 id="parameter-logging-vm-execution">[parameter] <code>*logging-vm-execution*</code></h2>
<p>This parameter is useful for printing how all instructions are performed. If set to T, all results and arguments produced by executing <code>cl-waffe2 IR</code> is displayed into the terminal. In default, set to nil.</p>
<h2 id="struct-wfinstruction">[struct] WfInstruction</h2>
<p>WfInstruction is IR for cl-waffe2 VM. Its form is represented by an extended Wengert list which is able to return multiple outputs. In this document, we call this <em>cl-waffe2 IR</em>, and compiled cl-waffe2 code, that is, the list of WfInstruction is called <strong>InstructionSeq</strong> or <strong>iseq</strong>. Unlike other frameworks, this IR is not only used to represent backpropagation but also forward propagation.</p>
<p>In cl-waffe2, WfInstruction is created by compiling AbstractNode, and its operation can be obtained by compiling lisp code or passing lambda functions.</p>
<p>A single WfInstruction represents:</p>
<pre><code>out_to[0], out_to[1], ... &lt;- λ(Args[0], Args[1], Args[2], ...)
 ^wfop-out-to                 ^wfop-op     ^wfop-args
</code></pre>
<p>where λ represents the operation. And, if any, <code>ArgsN</code> is wrapped with <code>SV4BW</code>.</p>
<pre><code>out_to[0], out_to[1], ... &lt;- λ(SV4BW(Args[0]), Args[1], Args[2], ...)
                                  ^ wfop-sv4bw
</code></pre>
<p>SV4BW (i.e: save-for-backward) is a temporary tensor to compute backwards and cl-waffe2 reads the <code>:save-for-backward</code> slots in the <code>define-impl</code> macro, and the corresponding tensors are copied.</p>
<h3 id="slots">Slots</h3>
<p><code>wfop-op[function]</code> corresponds with compiled λ function.</p>
<p><code>wfop-node[AbstractNode or string or function]</code> The node which generates λ function. For the most case, this slot is set to <code>AbstractNode</code>, but the node is something special, (e.g.: <code>CodeBlock</code>, <code>IfNode</code> etc...), set to <code>function</code>.</p>
<p><code>wfop-out-to[list of AbstractTensor]</code> indicates list of tensors that results are to be stored.</p>
<p><code>wfop-self[AbstractTensor]</code> corresponds with <code>out_target</code>, that is, the tensor to store the results</p>
<p><code>wfop-args[list of AbstractTensor]</code> corresponds with <code>(tensor-variable wfop-self)</code>. tensors to be called with: <code>arg1 arg2 arg3...</code>.</p>
<p><code>wfop-sv4bw[list of AbstractTensor]</code> indicates list of tensors storing save-for-backward tensors. if the corresponding position is <code>save-for-backward=nil</code>, the corresponding position also become nil.</p>
<h2 id="function-compile-forward-and-backward">[function] compile-forward-and-backward</h2>
<pre><code class="language-lisp">(compile-forward-and-backward toplevel &amp;key (need-backward t) (fuse-p t) (compile-mode :default) (optimize-locality t))
</code></pre>
<p>Compiles into cl-waffe2 IR (so-called iseq) from the given toplevel to each leaf points (where detach-p=t or backward=null variables). <code>toplevel</code> is AbstractTensor with backwards.</p>
<p>Tips: <code>disassemble-waffe2-ir</code> to display compiled Instruction Sequence.</p>
<h3 id="return">Return</h3>
<p><code>(values forward-iseq backward-iseq leaves[an list of AbstractTensor that appeared in the node] dout alloc-state)</code></p>
<h2 id="function-accept-instructions">[function] accept-instructions</h2>
<pre><code class="language-lisp">(accept-instructions iseq)
</code></pre>
<p>Evaluates generated cl-waffe2 IR sequence.</p>
<p><code>iseq[list]</code> an list of <code>WFInstruction</code></p>
<h2 id="function-disassemble-waffe2-ir">[function] disassemble-waffe2-ir</h2>
<pre><code class="language-lisp">(disassemble-waffe2-ir toplevel &amp;key (backward t) (stream t) (fuse-p t))
</code></pre>
<p>Prints out the compiled cl-waffe2 IR from toplevel to each leaf points to <code>stream</code>. If <code>backward</code> was set to t, <code>backward</code> is also displayed.</p>
<h3 id="example">Example</h3>
<pre><code class="language-lisp">(with-output-to-string (out)
    (disassemble-waffe2-ir (!softmax (parameter (randn `(3 3))) :avoid-overflow nil) :stream out))


disassemble-waffe2-ir:
 [Forward]: 
&lt;WfInst[op=ALLOC{INTERNAL}]     : TID341 &lt;= op(TID341{float, (3 3)} &lt;Param&gt;TID336{float, (3 3)})&gt;
&lt;WfInst[op=EXPNODE-CPUTENSOR]   : TID341 &lt;= op(&lt;Param&gt;SV4BW(TID336{float, (3 3)}) TID341{float, (3 3)})&gt;
&lt;WfInst[op=SCALARMUL-CPUTENSOR] : TID371 &lt;= op(TID371{float, (3 1)} &lt;Input&gt;TID363{float, (1)})&gt;
&lt;WfInst[op=VIEWTENSORNODE-T]    : TID371 &lt;= op(TID371{float, (3 3)} TID371{float, (3 1)})&gt;
&lt;WfInst[op=ADDNODE-CPUTENSOR]   : TID371 &lt;= op(TID371{float, (3 3)} TID341{float, (3 3)})&gt;
&lt;WfInst[op=DIVNODE-CPUTENSOR]   : TID341 &lt;= op(SV4BW(TID341{float, (3 3)}) SV4BW(TID371{float, (3 3)}))&gt;

6 Instructions | 3 Tensors | 1 Scalars


 [Pullback]: 
&lt;WfInst[op=MOVETENSORNODE-CPUTENSOR]       : TID430 &lt;= op(TID430{float, (3 3)} &lt;Input&gt;TID427{float, (3 3)})&gt;
&lt;WfInst[op=DIVNODE-CPUTENSOR]              : TID430 &lt;= op(TID430{float, (3 3)} TID408{float, (3 3)})&gt;
&lt;WfInst[op=MOVETENSORNODE-CPUTENSOR]       : TID458 &lt;= op(TID458{float, (3 3)} &lt;Input&gt;TID427{float, (3 3)})&gt;
&lt;WfInst[op=SCALARMUL-CPUTENSOR]            : TID458 &lt;= op(TID458{float, (3 3)} &lt;Input&gt;TID455{float, (1)})&gt;
&lt;WfInst[op=MULNODE-CPUTENSOR]              : TID403 &lt;= op(TID403{float, (3 3)} TID458{float, (3 3)})&gt;
&lt;WfInst[op=VIEWTENSORNODE-T]               : TID408 &lt;= op(TID408{float, (3 3)} TID408{float, (3 1)})&gt;
&lt;WfInst[op=MULNODE-CPUTENSOR]              : TID408 &lt;= op(TID408{float, (3 3)} TID408{float, (3 3)})&gt;
&lt;WfInst[op=DIVNODE-CPUTENSOR]              : TID403 &lt;= op(TID403{float, (3 3)} TID408{float, (3 3)})&gt;
&lt;WfInst[op=SYSTEM-LAZY-CONS-T]             : TID430 TID403 &lt;= op(TID430{float, (3 3)} TID403{float, (3 3)})&gt;
&lt;WfInst[op=EXPNODE-CPUTENSOR]              : TID351 &lt;= op(TID351{float, (3 3)} TID351{float, (3 3)})&gt;
&lt;WfInst[op=MULNODE-CPUTENSOR]              : TID430 &lt;= op(TID430{float, (3 3)} TID351{float, (3 3)})&gt;
&lt;WfInst[op={GRAD}MOVETENSORNODE-CPUTENSOR] : &lt;Input&gt;TID338 &lt;= op(&lt;Input&gt;TID338{float, (3 3)} TID430{float, (3 3)})&gt;

12 Instructions | 7 Tensors | 1 Scalars


</code></pre>
<h2 id="function-benchmark-accept-instructions">[function] benchmark-accept-instructions</h2>
<pre><code class="language-lisp">(benchmark-accept-instructions iseq &amp;key (n-sample 1) (ignore-first-call nil) (stream t) (top-k 10))
</code></pre>
<p>Basically, the function <code>benchmark-accept-instruction</code> executes the given list of instructions with profiling execution time, but at the end of proess, displays the report into <code>stream</code>.</p>
<h3 id="inputs">Inputs</h3>
<p><code>n-sample[fixnum]</code> repeats the iseq execution for <code>n-sample</code> times</p>
<p><code>ignore-first-call[boolean]</code> If t, ignores the first call to avoid including allocating time.</p>
<p><code>stream[stream]</code> the place to display the result</p>
<p><code>top-k[fixnum]</code> top-k slowest nodes are displayed at the end of report.</p>
<h3 id="return_1">Return</h3>
<p><code>result[AbstractTensor]</code></p>
<p>See also: <code>proceed-bench</code></p>
<h3 id="example_1">Example</h3>
<pre><code class="language-lisp">(with-output-to-string (out)
    (proceed-bench (!softmax (randn `(100 100))) :n-sample 100 :stream out))

[Sorted by Instructions]
 Time(s)   |   Instruction ( * - Beyonds the average execution time)
4.83e-4    | &lt;WfInst[op=MOVETENSORNODE-CPUTENSOR] : TID693 &lt;= op(TID693{float, (100 100)} &lt;Input&gt;TID609{float, (100 100)})&gt;
1.32e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID687 &lt;= op(TID687{float, (100 1)} TID687{float, (100 1)})&gt;
2.55e-4    | &lt;WfInst[op=SCALARMUL-CPUTENSOR]      : TID687 &lt;= op(TID687{float, (100 1)} &lt;Input&gt;TID618{float, (1)})&gt;
1.24e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID687 &lt;= op(TID687{float, (100 100)} TID687{float, (100 1)})&gt;
0.007934*  | &lt;WfInst[op=ADDNODE-CPUTENSOR]        : TID687 &lt;= op(TID687{float, (100 100)} &lt;Input&gt;TID609{float, (100 100)})&gt;
1.44e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID687 &lt;= op(TID687{float, (100 1)} TID687{float, (100 100)})&gt;
0.00277*   | &lt;WfInst[op=SCALARDIV-CPUTENSOR]      : TID687 &lt;= op(TID687{float, (100 1)} &lt;Input&gt;TID613{float, (1)})&gt;
1.27e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID687 &lt;= op(TID687{float, (100 100)} TID687{float, (100 1)})&gt;
0.005669*  | &lt;WfInst[op=SUBNODE-CPUTENSOR]        : TID693 &lt;= op(TID693{float, (100 100)} TID687{float, (100 100)})&gt;
0.001311   | &lt;WfInst[op=EXPNODE-CPUTENSOR]        : TID693 &lt;= op(TID693{float, (100 100)} TID693{float, (100 100)})&gt;
2.88e-4    | &lt;WfInst[op=SCALARMUL-CPUTENSOR]      : TID687 &lt;= op(TID687{float, (100 1)} &lt;Input&gt;TID738{float, (1)})&gt;
1.24e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID687 &lt;= op(TID687{float, (100 100)} TID687{float, (100 1)})&gt;
0.007932*  | &lt;WfInst[op=ADDNODE-CPUTENSOR]        : TID687 &lt;= op(TID687{float, (100 100)} TID693{float, (100 100)})&gt;
0.006103*  | &lt;WfInst[op=DIVNODE-CPUTENSOR]        : TID693 &lt;= op(TID693{float, (100 100)} TID687{float, (100 100)})&gt;

14 Instructions | 6 Tensors | Overheads due to SV4BW(...) -&gt; 6.96e-6(s) 

 Total Time: 0.033396002 sec

[Sorted by topK]
 Instruction                         | Total time (s) | Time/Total (n-sample=100)
&lt;WfInst[op=ADDNODE-CPUTENSOR]        | 0.015866       | 47.508682%
&lt;WfInst[op=DIVNODE-CPUTENSOR]        | 0.006103       | 18.274643%
&lt;WfInst[op=SUBNODE-CPUTENSOR]        | 0.005669       | 16.975086%
&lt;WfInst[op=SCALARDIV-CPUTENSOR]      | 0.00277        | 8.294406%
&lt;WfInst[op=EXPNODE-CPUTENSOR]        | 0.001311       | 3.9256196%
&lt;WfInst[op=VIEWTENSORNODE-T]         | 6.5100007e-4   | 1.9493352%
&lt;WfInst[op=SCALARMUL-CPUTENSOR]      | 5.43e-4        | 1.6259432%
&lt;WfInst[op=MOVETENSORNODE-CPUTENSOR] | 4.83e-4        | 1.446281%

</code></pre>
<h2 id="struct-fusionpathquery">[struct] FusionPathQuery</h2>
<pre><code class="language-lisp">(make-query abstract-node &amp;key (device t) (dtype t) (pred #'(lambda (node) t)))
</code></pre>
<p><code>(make-query ...)</code> and create a new query.</p>
<p>A single <code>FusionPathQuery</code> becomes t only when satisfies all of following conditions:</p>
<p><code>abstract-node[symbol]</code> become t when the node is a subtype of <code>abstract-node</code></p>
<p><code>device[t or symbol]</code>   become t when the node is working under the device or <code>subtype</code> of it.</p>
<p><code>dtype[t or list]</code>      become t when the <code>dtype</code> is set to t, or the list of dtype in arguments are corresponds with the list. (e.g.: <code>(list :float :float)</code>)</p>
<p><code>pred[function]</code>        specifies an additional predicator, the function receives <code>(node)</code> as arguments and return t to accept it. (<code>arguments-tensor</code> is an list of tensors, which <code>forward</code> or <code>call</code> used.)</p>
<p>This structure is excepted to be combined with <code>defpath</code>.</p>
<h2 id="macro-defpath">[macro] defpath</h2>
<pre><code class="language-lisp">(defpath (fusion-name &amp;rest query-list) &amp;key (reject-p #'(lambda ())) (replaced-with nil))
</code></pre>
<p>⚠️ This API is still in the conceptial stage, tests are not enough. DO NOT USE THIS.</p>
<p>The macro defpath introduces to cl-waffe2 <strong>Symbolic Differentiation</strong>. Users can define a <code>FusionQueryPath</code> to relocate compiled instructions with reference to the search. Composing the sequence of generated IRs to suit the device or model is the easiest way to speed up your model, cl-waffe2 searches for compiled nodes and replaces those matching the conditions specified in <code>query-list</code> with the computed nodes specified in <code>replaced-with</code>, if <code>:fuse-p</code> is set to t (default: <code>t</code>). In the simplest case, <code>defpath</code> can detect <code>[AddNode-CPUTensor] [MulNode-CPUTensor]</code> sequence and replace it with <code>[AddMulNode-CPUTensor]</code> node to reduce the number of instructions.</p>
<pre><code class="language-lisp">[When adding a new device to cl-waffe2...]
 1. Declare the new device (e.g.: CPUTensor, CUDATensor ...)
 2. Prepare allocator and accessors (e.g.: initialize-instance method, vref and (setf vref))
 3. Implement existing operations with define-impl macro
 4. Blush up the generated IR with defpath macro to fuse more operations in a small cycle. &lt;- defpath, here!
</code></pre>
<p>The created and registered path, will be reset with the <code>(reset-all-path!)</code> function. All registered paths are stored in <code>*user-defined-path-list*</code> parameter.</p>
<h3 id="rules">Rules</h3>
<p>cl-waffe2 replaces the existing operations with following the rules:</p>
<ol>
<li>The search is performed ignoring SaveForBackwardNode. If it is contained in the area to be replaced, it is moved to the last sequence of replaced one.</li>
</ol>
<pre><code class="language-lisp">;; Example
Rule: [A] [B] -&gt; [C]
</code></pre>
<pre><code class="language-lisp">Before Fusion:

[A]
[SAVE_FOR_BACKWARD]
[B]
[M]
[N]
</code></pre>
<pre><code class="language-lisp">Searching will be done ignoring [SAVE_FOR_BACKWARD]

^ [A]
| [B]
| [M]
| [N]
reading in this direction.
</code></pre>
<pre><code class="language-lisp">After fusion:

[C]  ;; [A] [B] -&gt; [C]
[SAVE_FOR_BACKWARD] ;; placed after the operation
[M]
[N]
</code></pre>
<ol>
<li><code>defpath</code> priority is given to those registered first.</li>
</ol>
<p>Repeat the search until no more targets are found to replace it.</p>
<ol>
<li>query-list</li>
</ol>
<p>Not replaced until the <code>query-list</code> matches everything, including the order.</p>
<h3 id="example_2">Example</h3>
<p>(TODO: For the case of ReLU)</p>
<h3 id="make-query">make-query</h3>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../generic-tensor/" class="btn btn-neutral float-left" title="cl-waffe2/vm.generic-tensor"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../base-impl/" class="btn btn-neutral float-right" title="[Functions] cl-waffe2/base-impl">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../generic-tensor/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../base-impl/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
