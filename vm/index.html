<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>cl-waffe2/vm - cl-waffe2 Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "cl-waffe2/vm";
        var mkdocs_page_input_path = "vm.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> cl-waffe2 Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Overview</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../install/">Install</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../overview/">Tutorials</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utils/">cl-waffe2</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../nodes/">cl-waffe2/vm.nodes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../generic-tensor/">cl-waffe2/vm.generic-tensor</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">cl-waffe2/vm</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#parameter-opt-level">[parameter] *opt-level*</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#parameter-logging-vm-execution">[parameter] *logging-vm-execution*</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#struct-wfinstruction">[struct] WfInstruction</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#slots">Slots</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-compile-forward-and-backward">[function] compile-forward-and-backward</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#return">Return</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-accept-instructions">[function] accept-instructions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-disassemble-waffe2-ir">[function] disassemble-waffe2-ir</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#example">Example</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-benchmark-accept-instructions">[function] benchmark-accept-instructions</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#inputs">Inputs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#return_1">Return</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example_1">Example</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../base-impl/">[Functions] cl-waffe2/base-impl</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../base-impl-nodes/">[Nodes] cl-waffe2/base-impl</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../distributions/">cl-waffe2/distributions</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../nn/">cl-waffe2/nn</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../optimizer/">cl-waffe2/optimizers</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../lisp-tensor-backend/">cl-waffe2/backends.lisp</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cpu-tensor-backend/">cl-waffe2/backends.cpu</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cpu-jit-tensor-backend/">cl-waffe2/backends.jit.cpu</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">cl-waffe2 Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li>cl-waffe2/vm</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="cl-waffe2-vm">cl-waffe2 VM</h1>
<p>The package <code>cl-waffe2/vm</code> is the central of system, and features are focused on low-level stuffs: compiling/optimizing/rewriting cl-waffe2 IRs and how they're executed. So, most of APIs are accesible by convinient API wrappers of other packages.</p>
<ul>
<li>Global Variables<ul>
<li><a href="./#parameter-opt-level">optimization level</a></li>
<li><a href="./#parameter-logging-vm-execution">logging</a></li>
</ul>
</li>
<li>IR and Compiler<ul>
<li><a href="./#struct-wfinstruction">WfInstruction</a></li>
<li><a href="./#function-compile-forward-and-backward">compiler</a></li>
<li><a href="./#function-accept-instructions">acceptor</a></li>
</ul>
</li>
<li>Analyzing compiled codes<ul>
<li><a href="#function-disassemble-waffe2-ir">disassemble</a></li>
<li><a href="#function-benchmark-accept-instructions">profiling</a></li>
</ul>
</li>
</ul>
<h2 id="parameter-opt-level">[parameter] <code>*opt-level*</code></h2>
<p>This parameter indicates the degree of runtime error detection. Whichever you choose, cl-waffe2 never apply something unsafe code transformation. It takes the fixnum from 1 to 3, and the larger, the faster.</p>
<ul>
<li>
<p>Set 1 to use safety-mode, in every instructions, runtime error is checked.</p>
</li>
<li>
<p>Set 2 to use middle-mode, runtime error is checked only when first execution.</p>
</li>
<li>
<p>Set 3 to use fastest-mode, no runtime error checking is done.</p>
</li>
</ul>
<p>Again, whichever levels you choose, the graph cl-waffe2 executes is the same. So the effects on the performance is very small (within &lt; <code>1e-4~1e-5</code> sec).</p>
<p>In default, set to 2.</p>
<h2 id="parameter-logging-vm-execution">[parameter] <code>*logging-vm-execution*</code></h2>
<p>This parameter is useful for printing how all instructions are performed. If set to T, all results and arguments produced by executing <code>cl-waffe2 IR</code> is displayed into the terminal. In default, set to nil.</p>
<h2 id="struct-wfinstruction">[struct] WfInstruction</h2>
<p>WfInstruction is IR for cl-waffe2 VM. Its form is represented by an extended Wengert list which is able to return multiple outputs. In this document, we call this <em>cl-waffe2 IR</em>, and compiled cl-waffe2 code, that is, the list of WfInstruction is called <strong>InstructionSeq</strong> or <strong>iseq</strong>. Unlike other frameworks, this IR is not only used to represent backpropagation but also forward propagation.</p>
<p>In cl-waffe2, WfInstruction is created by compiling AbstractNode, and its operation can be obtained by compiling lisp code or passing lambda functions.</p>
<p>A single WfInstruction represents:</p>
<pre><code>out_to[0], out_to[1], ... &lt;- λ(Args[0], Args[1], Args[2], ...)
 ^wfop-out-to                 ^wfop-op     ^wfop-args
</code></pre>
<p>where λ represents the operation. And, if any, <code>ArgsN</code> is wrapped with <code>SV4BW</code>.</p>
<pre><code>out_to[0], out_to[1], ... &lt;- λ(SV4BW(Args[0]), Args[1], Args[2], ...)
                                  ^ wfop-sv4bw
</code></pre>
<p>SV4BW (i.e: save-for-backward) is a temporary tensor to compute backwards and cl-waffe2 reads the <code>:save-for-backward</code> slots in the <code>define-impl</code> macro, and the corresponding tensors are copied.</p>
<h3 id="slots">Slots</h3>
<p><code>wfop-op[function]</code> corresponds with compiled λ function.</p>
<p><code>wfop-node[AbstractNode or string or function]</code> The node which generates λ function. For the most case, this slot is set to <code>AbstractNode</code>, but the node is something special, (e.g.: <code>CodeBlock</code>, <code>IfNode</code> etc...), set to <code>function</code>.</p>
<p><code>wfop-out-to[list of AbstractTensor]</code> indicates list of tensors that results are to be stored.</p>
<p><code>wfop-self[AbstractTensor]</code> corresponds with <code>out_target</code>, that is, the tensor to store the results</p>
<p><code>wfop-args[list of AbstractTensor]</code> corresponds with <code>(tensor-variable wfop-self)</code>. tensors to be called with: <code>arg1 arg2 arg3...</code>.</p>
<p><code>wfop-sv4bw[list of AbstractTensor]</code> indicates list of tensors storing save-for-backward tensors. if the corresponding position is <code>save-for-backward=nil</code>, the corresponding position also become nil.</p>
<h2 id="function-compile-forward-and-backward">[function] compile-forward-and-backward</h2>
<pre><code class="language-lisp">(compile-forward-and-backward toplevel &amp;key (need-backward t) (fuse-p t) (compile-mode :default) (optimize-locality t))
</code></pre>
<p>Compiles into cl-waffe2 IR (so-called iseq) from the given toplevel to each leaf points (where detach-p=t or backward=null variables). <code>toplevel</code> is AbstractTensor with backwards.</p>
<p>Tips: <code>disassemble-waffe2-ir</code> to display compiled Instruction Sequence.</p>
<h3 id="return">Return</h3>
<p><code>(values forward-iseq backward-iseq leaves[an list of AbstractTensor that appeared in the node] dout alloc-state)</code></p>
<h2 id="function-accept-instructions">[function] accept-instructions</h2>
<pre><code class="language-lisp">(accept-instructions iseq)
</code></pre>
<p>Evaluates generated cl-waffe2 IR sequence.</p>
<p><code>iseq[list]</code> an list of <code>WFInstruction</code></p>
<h2 id="function-disassemble-waffe2-ir">[function] disassemble-waffe2-ir</h2>
<pre><code class="language-lisp">(disassemble-waffe2-ir toplevel &amp;key (backward t) (stream t) (fuse-p t))
</code></pre>
<p>Prints out the compiled cl-waffe2 IR from toplevel to each leaf points to <code>stream</code>. If <code>backward</code> was set to t, <code>backward</code> is also displayed.</p>
<h3 id="example">Example</h3>
<pre><code class="language-lisp">(with-output-to-string (out)
    (disassemble-waffe2-ir (!softmax (parameter (randn `(3 3))) :avoid-overflow nil) :stream out))


disassemble-waffe2-ir:
 [Forward]: 
&lt;WfInst[op=ALLOC{INTERNAL}]     : TID481 &lt;= op(TID481{float, (3 3)} &lt;Param&gt;TID476{float, (3 3)})&gt;
&lt;WfInst[op=EXPNODE-CPUTENSOR]   : TID481 &lt;= op(&lt;Param&gt;SV4BW(TID476{float, (3 3)}) TID481{float, (3 3)})&gt;
&lt;WfInst[op=SCALARMUL-CPUTENSOR] : TID511 &lt;= op(TID511{float, (3 1)} &lt;Input&gt;TID503{float, (1)})&gt;
&lt;WfInst[op=VIEWTENSORNODE-T]    : TID511 &lt;= op(TID511{float, (3 3)} TID511{float, (3 1)})&gt;
&lt;WfInst[op=ADDNODE-CPUTENSOR]   : TID511 &lt;= op(TID511{float, (3 3)} TID481{float, (3 3)})&gt;
&lt;WfInst[op=DIVNODE-CPUTENSOR]   : TID481 &lt;= op(SV4BW(TID481{float, (3 3)}) SV4BW(TID511{float, (3 3)}))&gt;

6 Instructions | 3 Tensors | 1 Scalars


 [Pullback]: 
&lt;WfInst[op=MOVETENSORNODE-CPUTENSOR] : TID569 &lt;= op(TID569{float, (3 3)} &lt;Input&gt;TID566{float, (3 3)})&gt;
&lt;WfInst[op=DIVNODE-CPUTENSOR]        : TID569 &lt;= op(TID569{float, (3 3)} TID548{float, (3 3)})&gt;
&lt;WfInst[op=MOVETENSORNODE-CPUTENSOR] : TID597 &lt;= op(TID597{float, (3 3)} &lt;Input&gt;TID566{float, (3 3)})&gt;
&lt;WfInst[op=SCALARMUL-CPUTENSOR]      : TID597 &lt;= op(TID597{float, (3 3)} &lt;Input&gt;TID594{float, (1)})&gt;
&lt;WfInst[op=MULNODE-CPUTENSOR]        : TID543 &lt;= op(TID543{float, (3 3)} TID597{float, (3 3)})&gt;
&lt;WfInst[op=VIEWTENSORNODE-T]         : TID548 &lt;= op(TID548{float, (3 3)} TID548{float, (3 1)})&gt;
&lt;WfInst[op=MULNODE-CPUTENSOR]        : TID548 &lt;= op(TID548{float, (3 3)} TID548{float, (3 3)})&gt;
&lt;WfInst[op=DIVNODE-CPUTENSOR]        : TID543 &lt;= op(TID543{float, (3 3)} TID548{float, (3 3)})&gt;
&lt;WfInst[op=SYSTEM-LAZY-CONS-T]       : TID569 TID543 &lt;= op(TID569{float, (3 3)} TID543{float, (3 3)})&gt;
&lt;WfInst[op=EXPNODE-CPUTENSOR]        : TID491 &lt;= op(TID491{float, (3 3)} TID491{float, (3 3)})&gt;
&lt;WfInst[op=MULNODE-CPUTENSOR]        : TID569 &lt;= op(TID569{float, (3 3)} TID491{float, (3 3)})&gt;
&lt;WfInst[op={GRAD}SETQ{INTERNAL}]     : &lt;Input&gt;TID478 &lt;= op(&lt;Input&gt;TID478{float, (3 3)} TID569{float, (3 3)})&gt;

12 Instructions | 7 Tensors | 1 Scalars


</code></pre>
<h2 id="function-benchmark-accept-instructions">[function] benchmark-accept-instructions</h2>
<pre><code class="language-lisp">(benchmark-accept-instructions iseq &amp;key (n-sample 1) (ignore-first-call nil) (stream t) (top-k 10))
</code></pre>
<p>Basically, the function <code>benchmark-accept-instruction</code> executes the given list of instructions with profiling execution time, but at the end of proess, displays the report into <code>stream</code>.</p>
<h3 id="inputs">Inputs</h3>
<p><code>n-sample[fixnum]</code> repeats the iseq execution for <code>n-sample</code> times</p>
<p><code>ignore-first-call[boolean]</code> If t, ignores the first call to avoid including allocating time.</p>
<p><code>stream[stream]</code> the place to display the result</p>
<p><code>top-k[fixnum]</code> top-k slowest nodes are displayed at the end of report.</p>
<h3 id="return_1">Return</h3>
<p><code>result[AbstractTensor]</code></p>
<p>See also: <code>proceed-bench</code></p>
<h3 id="example_1">Example</h3>
<pre><code class="language-lisp">(with-output-to-string (out)
    (proceed-bench (!softmax (randn `(100 100))) :n-sample 100 :stream out))

[Sorted by Instructions]
 Time(s)   |   Instruction ( * - Beyonds the average execution time)
3.98e-4    | &lt;WfInst[op=MOVETENSORNODE-CPUTENSOR] : TID846 &lt;= op(TID846{float, (100 100)} &lt;Input&gt;TID762{float, (100 100)})&gt;
1.01e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID840 &lt;= op(TID840{float, (100 1)} TID840{float, (100 1)})&gt;
1.49e-4    | &lt;WfInst[op=SCALARMUL-CPUTENSOR]      : TID840 &lt;= op(TID840{float, (100 1)} &lt;Input&gt;TID771{float, (1)})&gt;
9.8e-5     | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID840 &lt;= op(TID840{float, (100 100)} TID840{float, (100 1)})&gt;
0.006252*  | &lt;WfInst[op=ADDNODE-CPUTENSOR]        : TID840 &lt;= op(TID840{float, (100 100)} &lt;Input&gt;TID762{float, (100 100)})&gt;
9.6e-5     | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID840 &lt;= op(TID840{float, (100 1)} TID840{float, (100 100)})&gt;
0.001905*  | &lt;WfInst[op=SCALARDIV-CPUTENSOR]      : TID840 &lt;= op(TID840{float, (100 1)} &lt;Input&gt;TID766{float, (1)})&gt;
9.4e-5     | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID840 &lt;= op(TID840{float, (100 100)} TID840{float, (100 1)})&gt;
0.004064*  | &lt;WfInst[op=SUBNODE-CPUTENSOR]        : TID846 &lt;= op(TID846{float, (100 100)} TID840{float, (100 100)})&gt;
9.78e-4    | &lt;WfInst[op=EXPNODE-CPUTENSOR]        : TID846 &lt;= op(TID846{float, (100 100)} TID846{float, (100 100)})&gt;
1.35e-4    | &lt;WfInst[op=SCALARMUL-CPUTENSOR]      : TID840 &lt;= op(TID840{float, (100 1)} &lt;Input&gt;TID891{float, (1)})&gt;
1.15e-4    | &lt;WfInst[op=VIEWTENSORNODE-T]         : TID840 &lt;= op(TID840{float, (100 100)} TID840{float, (100 1)})&gt;
0.006132*  | &lt;WfInst[op=ADDNODE-CPUTENSOR]        : TID840 &lt;= op(TID840{float, (100 100)} TID846{float, (100 100)})&gt;
0.004016*  | &lt;WfInst[op=DIVNODE-CPUTENSOR]        : TID846 &lt;= op(TID846{float, (100 100)} TID840{float, (100 100)})&gt;

14 Instructions | 6 Tensors | Overheads due to SV4BW(...) -&gt; 5.38e-6(s) 

 Total Time: 0.024533 sec

[Sorted by topK]
 Instruction                         | Total time (s) | Time/Total (n-sample=100)
&lt;WfInst[op=ADDNODE-CPUTENSOR]        | 0.012384       | 50.478947%
&lt;WfInst[op=SUBNODE-CPUTENSOR]        | 0.004064       | 16.565443%
&lt;WfInst[op=DIVNODE-CPUTENSOR]        | 0.004016       | 16.369787%
&lt;WfInst[op=SCALARDIV-CPUTENSOR]      | 0.001905       | 7.765051%
&lt;WfInst[op=EXPNODE-CPUTENSOR]        | 9.78e-4        | 3.9864671%
&lt;WfInst[op=VIEWTENSORNODE-T]         | 5.04e-4        | 2.054376%
&lt;WfInst[op=MOVETENSORNODE-CPUTENSOR] | 3.98e-4        | 1.6223047%
&lt;WfInst[op=SCALARMUL-CPUTENSOR]      | 2.84e-4        | 1.1576245%

</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../generic-tensor/" class="btn btn-neutral float-left" title="cl-waffe2/vm.generic-tensor"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../base-impl/" class="btn btn-neutral float-right" title="[Functions] cl-waffe2/base-impl">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../generic-tensor/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../base-impl/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
